---
title: "Matching w. the MOR2 HH Survey"
output:
  html_document: default
  html_notebook: default
---

```{r, message=FALSE}
library(MatchIt)
library(optmatch)
library(foreign)
library(dplyr)
library(tidyr)
library(ggplot2)
library(magrittr)
library(gridExtra)
library(Zelig)
library(knitr)
library(xtable)
library(ggjoy)
library(cobalt)
```

## TO DOs and reminders:
* fix RMD code to not print all the R code chunks along w the results...?
* insert ref to efa_cfa.Rmd exported pdf
* Qs re: latent means rescale then weighted---ok to interpret directly?

## General Notes on matching and propensity scores...

The goal of matching is to get trt and ctrl groups with similar distributions of covariates. Then when comparing trt effect on outcome , we can be more conifdent that we are actually detecting the impact of that trt (here it is CBRM or an individual practice) versus the confounding impact of the covariates. One advantage of matching methods is that we can identify areas where the covariate distributions do not sufficiently overlap, and exclude those samples from the subsequent analysis, as they would create additional bias (this is partic imp in subsequent linear modeling, etc.). Basically we are trying to reduce bias in our estimation of the effect of different "treatments" (practices, or institution)


The Standardized Diff in means should generally be < 0.25  (Some say 0.1)
Ratio of variances of the propensity scores should be around 1. 
Note: in matchIt the default label for propensity scores is "distance"
so that is often used below. 

Re: choosing variables for matching: "Include in the matching procedure any covariates that may be related to treatment assignment and the outcome"-(Stuart and Rubin 2007)
generally should not match on variables that are affected by the treatment assignment
Post-matching:
Use analyses appropriate for non-independent matched samples if more than one nonparticipant is matched to each participant
Note: When you have multiple matches for a single treated observation, it is essential to use Weighted Least Squares rather than OLS.
As the procedure only controls for observed variables, any hidden bias due to latent variables may remain after matching.
We are matching for a few different "treatments", each of which will be matched based on relevat covariates.
Starting first with CBRM status (Yes/No). We want to compare the outcomes re: ecological condition with this method compared to that of earlier studies that did not control for these confounding factors.  Then we will compare the ecological outcomes under individual practices (esp p4-p10).

One question: Should we just use exact matching for CBRM, since the original study was established to have a relatively balanced number of CBRM and non-CBRM households? 
Then potentially continue with full matching for the Practices 'treatments'?  
How best to include Trespassing? As a Trt? or a Covariate?

### Matching method
We are using 'optimal full matching', which will allow us to 

### Assessing balance
We

**Propensity score** :the probability of *receiving* the treatment, given the observed covriates. We want to ensure that the p-scores are as similar as we can, before we start to estimate the effect of a given treatment.  They summarize all of the covariates in to a single scalar-- at each value of p-score, the distribution of the covariates is the same in teh trt and cntrl groups.

### Variable selection
From Stuart (2010) "include all vars known to be related to treatment assignment, and the outcome"
and/or: include set of covariates known to be realted to the outcome var, then check the balance on all/additional covariates. Then add in any addtnl covariates that seem really unmatched.

**DO NOT** include covariate that might be affected by the treatment!

## Loading Data....
This includes MOR2 HH survey data, data from Jay Angerer on environmental parameters and forage availability and stockign density at the soum level.  And also the outcome variance, which I am generally referring to here as Ecological Integrity Index (please help me come up with a better name if you don't feel like that's a good choice). This Ecol Int Index value is the outcome of the Comfirmatory Factor Analysis (INSERT NAME OF the pdf once I've exported it from the Rmd). See that document for a description of the process of  generating the latent mean value for Ecological Integrity. The raw latent mean is scaled from -2 thru 2. I rescaled these values to be from 0-1. Then later they are weighted, resulting in a final range of values = [###].
--summary stats on that
--should these be set to quantiles?

```{r load, echo=FALSE, message=FALSE, cache = TRUE}
# STEP 1: subsetting the mor2 data:
# for use in matching....

# this is the data on just the 130 HH That have paired ecological data,along with their associated Organizational info
mor2<- read.spss("./data/ALL_EcolHHOrgMerged_byUvuljaa_03_15_17_Simplified.sav" , 
                 to.data.frame=TRUE,
                 use.value.labels=FALSE) #
# tidy format
tbl_df(mor2)

# load jay's data on env params
soum_stats<- readRDS("./soum_stats.rds")

# load the latent means from the CFA
#   these are the extracted latent means from the cfa of ecological variables
#   this file was generated in the efa_cfa.Rmd doc.
lvs<- readRDS("rpe_lv.R")
lvs$RefNum <- as.factor(lvs$RefNum)

hhmatch <- mor2 %>%
  dplyr ::select(CBRM,
         AimagName,
         SoumCode,
         SoumName,
         ez = EcologicalZone_4Code,
         RefNum = SocialSurveyReferenceNumber,
         Trsp = AnotherAilLSOnPast
         ) 
hhmatch%<>% mutate_at(c(1,4,6), funs(factor(.)))            # ordered(.)))
hhmatch$SoumName <- trimws(as.character(hhmatch$SoumName))
hhmatch$AimagName <- trimws(as.character(hhmatch$AimagName))


#tbl_df(lvs)
hhmatch %<>% left_join(lvs[,c(2,
                              7,
                              11:17,
                              22:24,
                              55
                              )], by= "RefNum")


hhmatch %<>% left_join(soum_stats, by = c("AimagName", "SoumName"))
# the "SoumID.x" that comes thru here is the Soum ID from Jay's jay, which do not match teh MOR2 codes, so i'm keeping them in for reference, just in case.
```

```{r}
# list of the params in the df
str(hhmatch)
```



# Matching: 

## CBRM as Treatment

```{r, message=FALSE}

#remove NAs

#hhmatch$SoumCode<- as.factor(hhmatch$SoumCode)

raw.data<- hhmatch %>% 
  na.omit() %>%
# rescale the response var from 0-1?
  mutate(eco.int = scales::rescale(eco.lv, to=c(0, 1)))   

#raw.data$CBRM<- raw.data$CBRM==0 

m.out1 <- matchit(CBRM ~ 
                    SoumCode+
                    Trsp+
                    ez + 
                    pl +
                    p2s +
                    p3s ,
                   # p4 +
                   #  p5 +
                   # p6 +
                   #  p7 +
                   #  p8 +
                   #  p9 ,   # get error if try to include these in addlvars
                    #p10, 
                  data =raw.data, 
                  method = "full", distance = "logit",
                  discard = "both"
                  )
m.full.summary<- summary(m.out1, 
                         standardize = TRUE)# ,  
                         #addlvariables = #match.data[,c("p4","p9", "p10")]) # why errors w this if try to include more than one at a time???
                                      
```
### get summary of matched data and generate dataset
If matching is done well, the treatment and control groups will have (near) identical means of each covariate at each value of the propensity score.
Reminder: we are assessing good match on St Diff in Means of matched groups <0.2 and var ratio around 1.  But since we know that some of these can vary based on more than just means we should also consider a test of their distributions (like Komologrov-Smirnoff)
```{r}
m.full.summary
# try to make a df out of that summary by calling indiv lists and then kable to table
full.data.m <- match.data(m.out1) # pulls matched data out of matchit object. 
## obtain matched data for the treatment group
#   keeping this here for reference in case need to export these later, but in general not using these separately
m.data.trt <- match.data(m.out1, group = "treat")
m.data.ctrl <- match.data(m.out1, group = "control")
```
### plotting to compare the matched v. unmatched data


```{r}
# this is done with balance.plot but see also Johan's code for his versions of plottin these
love.plot(bal.tab(m.out1), 
          stat = "mean.diffs",  # c("mean.diffs", "variance.ratios", "ks.statistics"), 
          # cant' get var ratios for binary vars... can't get this to work unless select one stat msr at a time.
          threshold = .2, 
          no.missing = TRUE,
          var.order = NULL)

bal.tab(m.out1, # the matchit object
        un = TRUE,  # print stats for unadjusted and adjusted sample?
        m.threshold = .1, # threshold for mean diffs. they suggest .1 which is more conservative than our 0.25 that we were using before
        int = FALSE, #include interactions?
        disp.means = TRUE,
        disp.v.ratio = TRUE,
        disp.ks =TRUE
        )
# 
b<- bal.plot(m.out1, "distance", which = "both")
# this returns a ggplot object
b+ theme_bw() # so just need to adjust the aesthetics.

```

### hidden extra plotting info that i'm saving.....
```{r, eval = FALSE}
# generate pre and post matching Std. Mean. Diff. datasets
# this is SUMMARY data
full.sum.all <- m.full.summary$sum.all
full.sum.mat <- m.full.summary$sum.matched
full.sum.all <- rename(full.sum.all, StMeanDiff = "Std. Mean Diff.")
full.sum.mat <- rename(full.sum.mat, StMeanDiff = "Std. Mean Diff.")


# write matching results files
write.csv(full.sum.all, "./data/matching/full_prematching_hh.csv")
write.csv(full.sum.mat, "./data/matching/full_postmatching_hh.csv")

# generate column for covariates
covariates <- row.names(m.full.summary$sum.all)

# generate dataset for plotting
#### ASK JOHAN ABOUT THIS ONE NOT SURE 
StMeanDif <- data.frame(cbind(covariates, full.sum.all$StMeanDiff, full.sum.mat$StMeanDiff))
StMeanDif <- data.frame(cbind(covariates, full.sum.all$StMeanDiff, full.sum.mat$StMeanDiff))
StMeanDif$V2 <- as.numeric(paste(StMeanDif$V2))
StMeanDif$V3 <- as.numeric(paste(StMeanDif$V3))

# plot Standardized mean differences
stmdif.full <- ggplot(StMeanDif, aes(y = covariates )) +
  geom_point(aes(x = V3), colour = "sienna4", size = 8, alpha = 1) + geom_point(aes(x = V3), colour = "orange", size = 6, alpha = 1) + # with replacement
  geom_point(aes(x = V2), colour = "black", size = 7, alpha = 1, shape = 1) +
  scale_x_continuous(limits=c(-1, 1), breaks = c(-1, -0.5, -0.25, 0, 0.25, 0.5, 1, 1.5, 2, 2.5)) +
  geom_vline(xintercept = 0, lty="dotted") +
  geom_vline(xintercept = -0.25, lty="dotted") +
  geom_vline(xintercept = 0.25, lty="dotted") +
  theme_classic() +
  xlab("Std. mean difference") +
  ylab("Matching covariates") +
  theme(axis.title.x = element_text(size=12, vjust=-0.2),
        axis.text.x = element_text(size=12),
        axis.title.y = element_text(size=12, vjust=1),
        axis.text.y = element_text(size=12),
        axis.line.x = element_line(color="black"),
        axis.line.y = element_line(color="black"))
stmdif.full


### generate propensity scores for full (unmatched) dataset

raw.data <- match.data
pscores <- glm(CBRM ~
              ez + 
              Trsp +
              #SoumCode+
              pl +
              p2s +
              p3s, # +
              # p4 +
              # p5 +
              # p6 +
              # p7 +
              # p8 +
              # p9 +
              # p10, 
            data = raw.data, family = binomial)


raw.data$ps <- predict(pscores, type = "response")

### Plot Propensity Scores before matching

full.pscore.pre <- ggplot(data=match.data) + 
  geom_density(data = raw.data[which(raw.data$CBRM == "0"), ], fill = "yellow3", color = "yellow4", alpha = 0.2, aes(x = ps)) +        
  geom_density(data = raw.data[which(raw.data$CBRM == "1"), ], fill = "navyblue", color = "mediumpurple4", alpha = 0.2, aes(x = ps)) + 
  xlim(-0.2, 1.2) +
#  ylim(0, 4) +       # set this to match the actual range of the data!!!!!
  theme_classic() +
  xlab("Propensity score") +
  ylab("Density") +
  ggtitle("Before Matching") +
  theme(axis.title.x = element_text(size=12, vjust=-0.2),
        axis.text.x = element_text(size=12),
        axis.title.y = element_text(size=12, vjust=1),
        axis.text.y = element_text(size=12),
        plot.title = element_text(size=18, face = "bold", hjust = 0.5),
        axis.line.x = element_line(color="black"),
        axis.line.y = element_line(color="black")
  )
full.pscore.pre

### Plot Propensity Scores after matching

full.pscore.post <- ggplot(data=full.data.m) + 
  geom_density(data = full.data.m[which(full.data.m$CBRM == "0"), ], fill = "yellow3", color = "yellow4", alpha = 0.2, aes(x = distance, weight = weights/sum(weights))) +
  geom_density(data = full.data.m[which(full.data.m$CBRM == "1"), ], fill = "navyblue", color = "mediumpurple4", alpha = 0.2, aes(x = distance)) +  # here distance = propensity score...
  xlim(-0.2, 1.2) +
#  ylim(0, 4) +
  theme_classic() +
  xlab("Propensity score") +
  ylab("Density") +
  ggtitle("After Matching") +
  theme(axis.title.x = element_text(size=12, vjust=-0.2),
        axis.text.x = element_text(size=12),
        axis.title.y = element_text(size=12, vjust=1),
        axis.text.y = element_text(size=12),
        plot.title = element_text(size=18, face = "bold", hjust = 0.5),
        axis.line.x = element_line(color="black"),
        axis.line.y = element_line(color="black")
  )
full.pscore.post


### plot matching figures

stmdif.full + scale_x_continuous(labels=scaleFUN)            # This should be 9" x 7" when exporting .pdf
grid.arrange(full.pscore.pre, full.pscore.post, ncol=1)      #  This should be 7" x 7" when exporting .pdf
```

# TRSP as Treatment

```{r data, message=FALSE}

#remove NAs

#hhmatch$SoumCode<- as.factor(hhmatch$SoumCode)

match.data<- hhmatch %>% 
  na.omit() %>%
# rescale the response var from 0-1?
  mutate(eco.int = scales::rescale(eco.lv, to=c(0, 1)))   

tr.full.summary<- summary(tr.out1 <- matchit(Trsp ~
                                          #CBRM + 
                                          ez + 
                                          pl +
                                          p2s +
                                          p3s +
                                          # p4 +
                                          # p5 +
                                          # p6 +
                                          # p7 +
                                          # p8 +
                                          # p9 +
                                          # p10 +
                                          ltmeanppt +
                                          ltmeansfu,
                                        data = match.data, 
                                        method = "full", distance = "logit",
                                        discard = "both"
                                        ), standardize = TRUE 
                                        )
# get summary and generate dataset
tr.full.summary
full.data.tr <- match.data(tr.out1) # pulls matched data out of matchit object. 
## obtain matched data for the treatment group
#tr.data.trt <- match.data(tr.out1, group = "treat")
#tr.data.ctrl <- match.data(tr.out1, group = "control")

# generate pre and post matching Std. Mean. Diff. datasets
trfull.sum.all <- tr.full.summary$sum.all         #sum.all is the pre-matching data
trfull.sum.mat <-tr.full.summary$sum.matched      #mat is after matching
# rename the col header to make it easier to call it later
trfull.sum.all <- rename(trfull.sum.all, StMeanDiff = "Std. Mean Diff.")
trfull.sum.mat <- rename(trfull.sum.mat, StMeanDiff = "Std. Mean Diff.")

# generate column for covariate names in the df, bc the output has the rows labelled but they aren't in a column
covariates <- row.names(tr.full.summary$sum.all)

# generate dataset for plotting
#### ASK JOHAN ABOUT THIS ONE NOT SURE 
StMeanDif <- data.frame(cbind(covariates, trfull.sum.all$StMeanDiff, trfull.sum.mat$StMeanDiff))
#StMeanDif <- data.frame(cbind(covariates, trfull.sum.all$StMeanDiff, trfull.sum.mat$StMeanDiff))
StMeanDif$V2 <- as.numeric(paste(StMeanDif$V2))
StMeanDif$V3 <- as.numeric(paste(StMeanDif$V3))


```
### Plot matching results:
```{r}
# plot Standardized mean differences
stmdif.full <- ggplot(StMeanDif, aes(y = covariates )) +
  geom_point(aes(x = V3), colour = "sienna4", size = 7, alpha = 1) + geom_point(aes(x = V3), colour = "orange", size = 6, alpha = 1) + # with replacement
  geom_point(aes(x = V2), colour = "black", size = 9, alpha = 1, shape = 1) +
  scale_x_continuous(limits=c(-1, 1.5), breaks = c(-1, -0.5, -0.25, 0, 0.25, 0.5, 1, 1.5, 2, 2.5)) +
  geom_vline(xintercept = 0, lty="dotted") +
  geom_vline(xintercept = -0.25, lty="dotted") +
  geom_vline(xintercept = 0.25, lty="dotted") +
  theme_classic() +
  xlab("Std. mean difference") +
  ylab("Matching covariates") +
  theme(axis.title.x = element_text(size=12, vjust=-0.2),
        axis.text.x = element_text(size=12),
        axis.title.y = element_text(size=12, vjust=1),
        axis.text.y = element_text(size=12),
        axis.line.x = element_line(color="black"),
        axis.line.y = element_line(color="black"))
stmdif.full
```

### balance.plot
```{r}
love.plot(bal.tab(tr.out1), 
          stat = "mean.diffs",  # c("mean.diffs", "variance.ratios", "ks.statistics"), 
          # cant' get var ratios for binary vars... can't get this to work unless select one stat msr at a time.
          threshold = .2, 
          no.missing = TRUE,
          var.order = NULL)

bal.tab(tr.out1, # the matchit object
        un = TRUE,  # print stats for unadjusted and adjusted sample?
        m.threshold = .1, # threshold for mean diffs. they suggest .1 which is more conservative than our 0.25 that we were using before
        int = FALSE, #include interactions?
        disp.means = TRUE,
        disp.v.ratio = TRUE,
        disp.ks =TRUE
        )
# 
b<- bal.plot(tr.out1, "distance", which = "both")
# this returns a ggplot object
b+ theme_bw() # so just need to adjust the aesthetics.

```

### generate propensity scores for full (unmatched) dataset
```{r}
pscores <- glm(Trsp ~
                ez + 
                pl +
                p2s +
                p3s +
                ltmeanppt +
                ltmeansfu,
            data = match.data, family = binomial)

match.data$ps <- predict(pscores, type = "response")

```
### Plot Propensity Scores 
```{r}
# before matching
full.pscore.pre <- ggplot(data=match.data) + 
  geom_density(data = match.data[which(match.data$CBRM == "0"), ], fill = "yellow3", color = "yellow4", alpha = 0.2, aes(x = ps)) +        
  geom_density(data = match.data[which(match.data$CBRM == "1"), ], fill = "navyblue", color = "mediumpurple4", alpha = 0.2, aes(x = ps)) + 
  xlim(-0.2, 1.2) +
#  ylim(0, 4) +       # set this to match the actual range of the data!!!!!
  theme_classic() +
  xlab("Propensity score") +
  ylab("Density") +
  ggtitle("Before Matching") +
  theme(axis.title.x = element_text(size=12, vjust=-0.2),
        axis.text.x = element_text(size=12),
        axis.title.y = element_text(size=12, vjust=1),
        axis.text.y = element_text(size=12),
        plot.title = element_text(size=18, face = "bold", hjust = 0.5),
        axis.line.x = element_line(color="black"),
        axis.line.y = element_line(color="black")
  )
#  after matching

full.pscore.post <- ggplot(data=full.data.m) + 
  geom_density(data = full.data.m[which(full.data.m$CBRM == "0"), ], fill = "yellow3", color = "yellow4", alpha = 0.2, aes(x = distance, weight = weights/sum(weights))) +
  geom_density(data = full.data.m[which(full.data.m$CBRM == "1"), ], fill = "navyblue", color = "mediumpurple4", alpha = 0.2, aes(x = distance)) +  # here distance = propensity score...
  xlim(-0.2, 1.2) +
#  ylim(0, 4) +
  theme_classic() +
  xlab("Propensity score") +
  ylab("Density") +
  ggtitle("After Matching") +
  theme(axis.title.x = element_text(size=12, vjust=-0.2),
        axis.text.x = element_text(size=12),
        axis.title.y = element_text(size=12, vjust=1),
        axis.text.y = element_text(size=12),
        plot.title = element_text(size=18, face = "bold", hjust = 0.5),
        axis.line.x = element_line(color="black"),
        axis.line.y = element_line(color="black")
  )
#full.pscore.post

#stmdif.full + scale_x_continuous(labels=scaleFUN)            # This should be 9" x 7" when exporting .pdf
grid.arrange(full.pscore.pre, full.pscore.post, ncol=1)      #  This should be 7" x 7" when exporting .pdf
```

## zelig stats...
```{r, eval = FALSE}
library(Zelig)
# run the parametric analysis
z.out<- zelig(eco.int ~ Trsp + CBRM + ez + pl + p2s +p3s +p4 +p5 +p6 +p7 +p8 +p9 + p10,model = "ls", data = full.data.tr)
#z.out<- zelig(eco.int ~ Trsp+ CBRM  + ez + pl + p2s +p3s ,model = "ls", data = full.data.m, weights = "weights")

# then set the explanatory variables at their means and change the trt var from a 0 to a 1
x.out <- setx(z.out, Trsp = 0)
x1.out<- setx(z.out, Trsp = 1)
# compute the result and examine a summary:
s.out <- sim(z.out, x = x.out, x1 = x1.out)

summary(s.out)
plot(s.out)
```
###  Estimate Avg Treatment Efffect on the Treated (where Trt = Trespassing)
predicts certain quantities of interest by conditioning on the observed value of the dependent variable  
In a matched sampling design, the sample average treatment effect for the treated can be estimated by computing the difference between the observed dependent variable for the treated group and their expected or predicted values of the dependent variable under no treatment 
```{r}
# fit model to control group only
z.out1<- zelig(eco.int ~ CBRM + ez + pl + p2s +p3s  +p5 +p6 +p7 +p8 +p9 + p10,#p4 was causing error
               model = "ls", data = match.data(tr.out1, "control"))
# conditional prediction which ues observed values
x.out2 <- setx(z.out1, data = match.data(tr.out1, "treat"), cond = TRUE) 
s.out2 <- sim(z.out1, x = x.out2)

summary(s.out2)
# output is ev = expected values, pv = predicted values
plot(s.out2)
```

### Estimate Average Treatment Effect: 


###  Estimate Avg Treatment Efffect on the Treated (where Trt = CBRM)
predicts certain quantities of interest by conditioning on the observed value of the dependent variable  
In a matched sampling design, the sample average treatment effect for the treated can be estimated by computing the difference between the observed dependent variable for the treated group and their expected or predicted values of the dependent variable under no treatment 
```{r, eval = FALSE}
# fit model to control group only
z.out1<- zelig(eco.int ~ CBRM + ez + pl + p2s +p3s +p4 +p5 +p6 +p7 +p8 +p9 + p10,model = "ls", data = match.data(tr.out1, "control"))
# conditional prediction which ues observed values
x.out2 <- setx(z.out1, data = match.data(tr.out1, "treat"), cond = TRUE) 
s.out2 <- sim(z.out1, x = x.out2)

summary(s.out2)
# output is ev = expected values, pv = predicted values
plot(s.out2)
```

# PRACTICES as Treatments...
## p4: fall Otor

To discuss w Maria: Which other vars to include for matching?
```{r P4,}

p4.full.summary<- summary(p4.out1 <- matchit(p4 ~
                                          CBRM + 
                                          ez + 
                                          #pl +
                                          #p2s +
                                          #p3s +
                                          #p5 +
                                          p6 +
                                          p7 +
                                          p8 ,#+
                                          # p9 +
                                          # p10 +
                                          #ltmeanppt+
                                          #ltmeansd, 
                                        data = raw.data, 
                                        method = "full", distance = "logit",
                                        discard = "both"
                                        ), standardize = TRUE  
                                        )
# get summary and generate dataset
p4.full.summary
full.data.p4 <- match.data(p4.out1) # pulls matched data out of matchit object. 
## obtain matched data for the treatment group
p4.data.trt <- match.data(p4.out1, group = "treat")
p4.data.ctrl <- match.data(p4.out1, group = "control")

# generate pre and post matching Std. Mean. Diff. datasets
p4full.sum.all <- p4.full.summary$sum.all         #sum.all is the pre-matching data
p4full.sum.mat <-p4.full.summary$sum.matched      #mat is after matching
# rename the col header to make it easier to call it later
p4full.sum.all <- rename(p4full.sum.all, StMeanDiff = "Std. Mean Diff.")
p4full.sum.mat <- rename(p4full.sum.mat, StMeanDiff = "Std. Mean Diff.")

# generate column for covariate names in the df, bc the output has the rows labelled but they aren't in a column
covariates <- row.names(p4.full.summary$sum.all)

# generate dataset for plotting
StMeanDif <- data.frame(cbind(covariates, p4full.sum.all$StMeanDiff, p4full.sum.mat$StMeanDiff))
StMeanDif$V2 <- as.numeric(paste(StMeanDif$V2))
StMeanDif$V3 <- as.numeric(paste(StMeanDif$V3))

```

balanace.plot
```{r}
love.plot(bal.tab(p4.out1), 
          stat =  "mean.diffs",   #c("mean.diffs", "variance.ratios", "ks.statistics"), 
          # cant' get var ratios for binary vars... can't get this to work unless select one stat msr at a time.
          threshold = .2,  #c(.2, 2), 
          no.missing = TRUE,
          var.order = NULL)

bal.tab(p4.out1, # the matchit object
        un = TRUE,  # print stats for unadjusted and adjusted sample?
        m.threshold = 0.2, #.1, # threshold for mean diffs. they suggest .1 which is more conservative than our 0.25 that we were using before
        int = FALSE, #include interactions?
        disp.means = TRUE,
        disp.v.ratio = TRUE,
        disp.ks =TRUE
        )
# 
b<- bal.plot(p4.out1, "distance", which = "both")
# this returns a ggplot object
b+ theme_bw() # so just need to adjust the aesthetics.

```

## p5: Winter Otor:

```{r P5,}

p5.full.summary<- summary(p5.out1 <- matchit(p5 ~
                                          CBRM + 
                                          ez + 
                                          #pl +
                                          #p2s +
                                          #p3s +
                                          #p4 +
                                          p6 +
                                          p7 +
                                          p8,# +
                                          # p9 +
                                          # p10 +
                                          #ltmeanppt+
                                          #ltmeansd, 
                                        data = raw.data, 
                                        method = "full", distance = "logit",
                                        discard = "both"
                                        ), standardize = TRUE  
                                        )
# get summary and generate dataset
p5.full.summary
full.data.p5 <- match.data(p5.out1) # pulls matched data out of matchit object. 
## obtain matched data for the treatment group
p5.data.trt <- match.data(p5.out1, group = "treat")
p5.data.ctrl <- match.data(p5.out1, group = "control")

```

## Balance plot
```{r}
love.plot(bal.tab(p5.out1), 
          stat =  "mean.diffs",   #c("mean.diffs", "variance.ratios", "ks.statistics"), 
          # cant' get var ratios for binary vars... can't get this to work unless select one stat msr at a time.
          threshold = .2,  #c(.2, 2), 
          no.missing = TRUE,
          var.order = NULL)

bal.tab(p5.out1, # the matchit object
        un = TRUE,  # print stats for unadjusted and adjusted sample?
        m.threshold = 0.2, #.1, # threshold for mean diffs. they suggest .1 which is more conservative than our 0.25 that we were using before
        int = FALSE, #include interactions?
        disp.means = TRUE,
        disp.v.ratio = TRUE,
        disp.ks =TRUE
        )
# 
b<- bal.plot(p5.out1, "distance", which = "both")
# this returns a ggplot object
b+ theme_bw() # so just need to adjust the aesthetics.


```

# p6: Reserve Winter Pastures:
```{r P6,}

p6.full.summary<- summary(p6.out1 <- matchit(p6 ~
                                          CBRM + 
                                          ez + 
                                          #pl +
                                          #p2s +
                                          #p3s +
                                          p4 +
                                          p5 + #+
                                          #p7 +
                                          #p8,# +
                                          # p9 +
                                          # p10 +
                                          ltmeanppt, #+
                                          #ltmeansd, 
                                        data = raw.data, 
                                        method = "full", distance = "logit",
                                        discard = "both"
                                        ), standardize = TRUE  
                                        )
# get summary and generate dataset
p6.full.summary
full.data.p6 <- match.data(p6.out1) # pulls matched data out of matchit object. 
## obtain matched data for the treatment group
p6.data.trt <- match.data(p6.out1, group = "treat")
p6.data.ctrl <- match.data(p6.out1, group = "control")

# balanace.plot

love.plot(bal.tab(p6.out1), 
          stat =  "mean.diffs",   #c("mean.diffs", "variance.ratios", "ks.statistics"), 
          # cant' get var ratios for binary vars... can't get this to work unless select one stat msr at a time.
          threshold = .2,  #c(.2, 2), 
          no.missing = TRUE,
          var.order = NULL)

bal.tab(p6.out1, # the matchit object
        un = TRUE,  # print stats for unadjusted and adjusted sample?
        m.threshold = 0.2, #.1, # threshold for mean diffs. they suggest .1 which is more conservative than our 0.25 that we were using before
        int = FALSE, #include interactions?
        disp.means = TRUE,
        disp.v.ratio = TRUE,
        disp.ks =TRUE
        )
# 
b<- bal.plot(p6.out1, "distance", which = "both")
# this returns a ggplot object
b+ theme_bw() # so just need to adjust the aesthetics.


```

# Grazing out of Season

## p9: Grazing winter pastures in summer and fall
```{r P9,}

p9.full.summary<- summary(p9.out1 <- matchit(p9 ~
                                          avail.forage+
                                          ltmeansfu+ 
                                          CBRM + 
                                          ez + 
                                          Trsp+
                                          pl +
                                          p2s +
                                          p3s +
                                          p4 +
                                          p5 + 
                                          p10,
                                        data = raw.data, 
                                        method = "full", 
                                        distance = "logit",
                                        discard = "both"
                                        ), standardize = TRUE  
                                        )
# get summary and generate dataset
p9.full.summary
full.data.p9 <- match.data(p9.out1) # pulls matched data out of matchit object. 
## obtain matched data for the treatment group
p9.data.trt <- match.data(p9.out1, group = "treat")
p9.data.ctrl <- match.data(p9.out1, group = "control")

# balanace.plot

love.plot(bal.tab(p9.out1), 
          stat =  "mean.diffs",   #c("mean.diffs", "variance.ratios", "ks.statistics"), 
          # cant' get var ratios for binary vars... can't get this to work unless select one stat msr at a time.
          threshold = .2,  #c(.2, 2), 
          no.missing = TRUE,
          var.order = NULL)

bal.tab(p9.out1, # the matchit object
        un = TRUE,  # print stats for unadjusted and adjusted sample?
        m.threshold = 0.2, #.1, # threshold for mean diffs. they suggest .1 which is more conservative than our 0.25 that we were using before
        int = FALSE, #include interactions?
        disp.means = TRUE,
        disp.v.ratio = TRUE,
        disp.ks =TRUE
        )
# 
b<- bal.plot(p9.out1, "distance", which = "both")
# this returns a ggplot object
b+ theme_bw() # so just need to adjust the aesthetics.


```
## p10: Grazing dzud pastures in non-emergency
```{r P10,}

p10.full.summary<- summary(p10.out1 <- matchit(p10 ~
                                          avail.forage+
                                          ltmeansfu+ 
                                          CBRM + 
                                          ez + 
                                          Trsp+
                                          pl +
                                          p2s +
                                          p3s +
                                          p4 +
                                          p5 + 
                                          p10,
                                        data = raw.data, 
                                        method = "full", 
                                        distance = "logit",
                                        discard = "both"
                                        ), standardize = TRUE  
                                        )
# get summary and generate dataset
p10.full.summary
full.data.p10 <- match.data(p10.out1) # pulls matched data out of matchit object. 
## obtain matched data for the treatment group
p10.data.trt <- match.data(p10.out1, group = "treat")
p10.data.ctrl <- match.data(p10.out1, group = "control")

# balanace.plot

love.plot(bal.tab(p10.out1), 
          stat =  "mean.diffs",   #c("mean.diffs", "variance.ratios", "ks.statistics"), 
          # cant' get var ratios for binary vars... can't get this to work unless select one stat msr at a time.
          threshold = .2,  #c(.2, 2), 
          no.missing = TRUE,
          var.order = NULL)

bal.tab(p10.out1, # the matchit object
        un = TRUE,  # print stats for unadjusted and adjusted sample?
        m.threshold = 0.2, #.1, # threshold for mean diffs. they suggest .1 which is more conservative than our 0.25 that we were using before
        int = FALSE, #include interactions?
        disp.means = TRUE,
        disp.v.ratio = TRUE,
        disp.ks =TRUE
        )
# 
b<- bal.plot(p10.out1, "distance", which = "both")
# this returns a ggplot object
b+ theme_bw() # so just need to adjust the aesthetics.


```

```{r, eval = FALSE}
p4data<-full.data.p4[complete.cases(full.data.p4),]
p4.mod<- glm(eco.int ~ p4 +
                        CBRM +
                        ez +
                        # pl +
                        # p2s +
                        # p3s +
                        # p5 +
                        p6 +
                        p7 +
                        p8 +
                        # p9 +
                        # p10 +
                        ltmeanppt+
                        ltsdppt,
              data = p4data, weights = "weights", family = poisson(link = "logit"))
             
p4.mod<- glm((eco.int*weights) ~ p4 +
          CBRM +
          ez +
          # pl +
          # p2s +
          # p3s +
          p5 +
          p6 +
          p7 +
          p8 +
          # p9 +
          # p10 +
          ltmeanppt+
          ltsdppt,
          data = p4data)
summary(p4.mod)
```



Try w zelig...
```{r, eval = FALSE}
# this uses the Zelig 5 process:
#z.out<- zls$new()

# this is Zelig4 still
z.out<- zelig(eco.int ~ p4 +
                        CBRM +
                        ez +
                        # pl +
                        # p2s +
                        # p3s +
                        # p5 +
                        p6 +
                        p7 +
                        p8 +
                        # p9 +
                        # p10 +
                        ltmeanppt+
                        ltmeansd, 
              model = "logit", data = full.data.p4, weights = "weights")
summary(z.out)
# then set the explanatory variables at their means and change the trt var from a 0 to a 1
x.out <- setx(z.out, p4 = 0)
x1.out<- setx(z.out, p4 = 1)
# compute the result and examine a summary:
s.out <- sim(z.out, x = x.out, x1 = x1.out)

summary(s.out)
## [1] "Expected Values: E(Y|X)"            
## [2] "Expected Values: E(Y|X1)"           
## [3] "Predicted Values: Y|X"              
## [4] "Predicted Values: Y|X1"             
## [5] "First Differences: E(Y|X1) - E(Y|X)"
plot(s.out)
```
In a matched sampling design, the sample average treatment effect for the treated can be estimated by computing the difference between the observed dependent variable for the treated group and their expected or predicted values of the dependent variable under no treatment.
SO compare the values of eco.int for P4=1 (in matched data or original raw??) vs. ev or pv of eco.int for p4=0


# Comparing distributions of post-matched data:

# CBRM
```{r}
cbrm_0<-(full.data.m$eco.int*full.data.m$weights)[which(full.data.m$CBRM==0)]
cbrm_1<-(full.data.m$eco.int*full.data.m$weights)[which(full.data.m$CBRM==1)]
plot(ecdf(cbrm_0))
lines(ecdf(cbrm_1), col = 'blue')

ks.test(cbrm_0, cbrm_1)
# Density plots
ggplot(full.data.m, aes(x=(eco.int*weights), colour=CBRM)) + geom_density()

# Means pre & post
full.data.m%>% group_by(CBRM)%>% summarise(pre= mean(eco.int), post= mean(eco.int*weights))

```
## Tresspassing:
```{r}

tr_0<- (full.data.tr$eco.int*full.data.tr$weights)[which(full.data.tr$Trsp==0)]
plot(ecdf(tr_0))

tr_1<- (full.data.tr$eco.int*full.data.tr$weights)[which(full.data.tr$Trsp==1)]
lines(ecdf(tr_1), col = 'blue')
abline(h = 0.5, lty = 2, col='black' )

ks.test(tr_0, tr_1)
# Look! One piece of evidence that they are different!

# Density plots
ggplot(full.data.tr, aes(x=(eco.int*weights), colour=as.factor(Trsp))) + geom_density()

# Means pre & post
full.data.tr%>% group_by(Trsp)%>% summarise(pre= mean(eco.int), post= mean(eco.int*weights))

full.data.tr%>% group_by(Trsp)%>% summarise(pre= median(eco.int), post= median(eco.int*weights))

```

## P4: Fall Otor
```{r}

p4_0<- (full.data.p4$eco.int*full.data.p4$weights)[which(full.data.p4$p4==0)]
plot(ecdf(p4_0))

p4_1<- (full.data.p4$eco.int*full.data.p4$weights)[which(full.data.p4$p4==1)]
lines(ecdf(p4_1), col = 'blue')

ks.test(p4_0, p4_1)
# Look! One piece of evidence that they are different!

# Density plots
ggplot(full.data.p4, aes(x=(eco.int*weights), colour=p4)) + geom_density()
# Means pre & post
full.data.p4%>% group_by(p4)%>% summarise(pre= mean(eco.int), post= mean(eco.int*weights))
```

# P5: Winter Otor
```{r}

p5_0<- (full.data.p5$eco.int*full.data.p5$weights)[which(full.data.p5$p5==0)]
plot(ecdf(p5_0))

p5_1<- (full.data.p5$eco.int*full.data.p5$weights)[which(full.data.p5$p5==1)]
lines(ecdf(p5_1), col = 'blue')

ks.test(p5_0, p5_1)
# Look! One piece of evidence that they are different!

# Density plots
ggplot(full.data.p5, aes(x=(eco.int*weights), colour=p5)) + geom_density()

# Means pre & post
full.data.p5%>% group_by(p5)%>% summarise(pre= mean(eco.int), post= mean(eco.int*weights))
```

# P6: Reserve Winter Pastures
```{r}

p6_0<- (full.data.p6$eco.int*full.data.p6$weights)[which(full.data.p6$p6==0)]
plot(ecdf(p6_0))

p6_1<- (full.data.p6$eco.int*full.data.p6$weights)[which(full.data.p6$p6==1)]
lines(ecdf(p6_1), col = 'blue')

ks.test(p6_0, p6_1)
# Look! One piece of evidence that they are different!

# Density plots
ggplot(full.data.p6, aes(x=(eco.int*weights), colour=p6)) + geom_density()

# Means pre & post
full.data.p6%>% group_by(p6)%>% summarise(pre= mean(eco.int), post= mean(eco.int*weights))
```

## P9: Grazed Winter-Sum/Fall
```{r}

p9_0<- (full.data.p9$eco.int*full.data.p9$weights)[which(full.data.p9$p9==0)]
plot(ecdf(p9_0))

p9_1<- (full.data.p9$eco.int*full.data.p9$weights)[which(full.data.p9$p9==1)]
lines(ecdf(p9_1), col = 'blue')

ks.test(p9_0, p9_1)
# 

# Density plots
ggplot(full.data.p9, aes(x=(eco.int*weights), colour=p9)) + geom_density()

# Means pre & post
full.data.p9%>% group_by(p9)%>% summarise(pre= mean(eco.int), post= mean(eco.int*weights))

full.data.p9%>% group_by(p9)%>% summarise(pre= median(eco.int), post= median(eco.int*weights))
```


### some useful links and references: 

Add Stuart & King cites here.

[cobalt vignette](https://cran.r-project.org/web/packages/cobalt/vignettes/cobalt_basic_use.html) 
[Stanford tutorial](https://stanford.edu/~ejdemyr/r-tutorials-archive/tutorial8.html) on propensity score matching.

[ggjoy](https://cran.r-project.org/web/packages/ggjoy/vignettes/introduction.html) vignette.
[xtable](https://cran.r-project.org/web/packages/xtable/vignettes/xtableGallery.pdf)

[zelig commands](https://r.iq.harvard.edu/docs/zelig/3.4-8/Zelig_Commands.html)

















